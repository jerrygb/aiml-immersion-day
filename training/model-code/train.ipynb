{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Place your conda yaml in the below section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "conda.yaml"
    ]
   },
   "outputs": [],
   "source": [
    "name: xgb-customer-churn\n",
    "channels:\n",
    "  - defaults\n",
    "  - anaconda\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - xgboost\n",
    "  - pip\n",
    "  - pip:\n",
    "      - mlflow>=1.6.0\n",
    "      - matplotlib\n",
    "      - boto3\n",
    "      - smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "tracking_uri = \"http://107.22.99.180/\"\n",
    "max_depth = 5\n",
    "eta = 0.2\n",
    "gamma = 4\n",
    "min_child_weight = 6\n",
    "eta = 0.2\n",
    "subsample = 0.8\n",
    "silent = 0\n",
    "objective = \"binary:logistic\"\n",
    "num_round = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place Imports \n",
    "\n",
    "Place all the imports that you are aware of here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.debugger import rule_configs, Rule, DebuggerHookConfig\n",
    "from sagemaker.model_monitor import DataCaptureConfig, DatasetFormat, DefaultModelMonitor\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Place the standalone functions in the below section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(local_data_path):\n",
    "    data = pd.read_csv(local_data_path)\n",
    "    pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "    pd.set_option('display.max_rows', 10)         # Keep the output on one page\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_smdebug_hook(out_dir, train_data=None, validation_data=None, frequency=1, collections=None,):\n",
    "\n",
    "    save_config = SaveConfig(save_interval=frequency)\n",
    "    hook = Hook(\n",
    "        out_dir=out_dir,\n",
    "        train_data=train_data,\n",
    "        validation_data=validation_data,\n",
    "        save_config=save_config,\n",
    "        include_collections=collections,\n",
    "    )\n",
    "\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(model_dir):\n",
    "    \"\"\"Load a model. For XGBoost Framework, a default function to load a model is not provided.\n",
    "    Users should provide customized model_fn() in script.\n",
    "    Args:\n",
    "        model_dir: a directory where model is saved.\n",
    "    Returns:\n",
    "        A XGBoost model.\n",
    "        XGBoost model format type.\n",
    "    \"\"\"\n",
    "    model_files = (file for file in os.listdir(model_dir) if os.path.isfile(os.path.join(model_dir, file)))\n",
    "    model_file = next(model_files)\n",
    "    try:\n",
    "        booster = pickle.load(open(os.path.join(model_dir, model_file), 'rb'))\n",
    "        format = 'pkl_format'\n",
    "    except Exception as exp_pkl:\n",
    "        try:\n",
    "            booster = xgboost.Booster()\n",
    "            booster.load_model(os.path.join(model_dir, model_file))\n",
    "            format = 'xgb_format'\n",
    "        except Exception as exp_xgb:\n",
    "            print(\"Unable to load model: {} {}\".format(str(exp_pkl), str(exp_xgb)))\n",
    "            import sys\n",
    "            sys.exit(-1)\n",
    "    booster.set_param('nthread', 1)\n",
    "    return booster, format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--max-depth\", type=int, default=5)\n",
    "    parser.add_argument(\"--eta\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--gamma\", type=int, default=4)\n",
    "    parser.add_argument(\"--min-child-weight\", type=int, default=6)\n",
    "    parser.add_argument(\"--subsample\", type=float, default=0.8)\n",
    "    parser.add_argument(\"--silent\", type=int, default=0)\n",
    "    parser.add_argument(\"--objective\", type=str, default=\"binary:logistic\")\n",
    "    parser.add_argument(\"--num-round\", type=int, default=50)\n",
    "    parser.add_argument(\"--smdebug-path\", type=str, default=None)\n",
    "    parser.add_argument(\"--smdebug-frequency\", type=int, default=1)\n",
    "    parser.add_argument(\"--smdebug-collections\", type=str, default='metrics')\n",
    "    parser.add_argument(\"--output-uri\", type=str, default=\"/opt/ml/output/tensors\",\n",
    "                        help=\"S3 URI of the bucket where tensor data will be stored.\")\n",
    "\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--validation', type=str, default=os.environ.get('SM_CHANNEL_VALIDATION'))\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR', '/opt/ml/model'))\n",
    "\n",
    "    print('\\n-------------- Environment Variables -------------\\n')\n",
    "    for key, value in os.environ.items():\n",
    "        print('{}={}'.format(key, value))\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(input_path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize total data\n",
    "\n",
    "Place all of the plots in the following section pertaining to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ignore"
    ]
   },
   "outputs": [],
   "source": [
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code\n",
    "\n",
    "Place training code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    args = parse_args()\n",
    "    # enable auto logging\n",
    "    mlflow.xgboost.autolog()\n",
    "    train, validation = args.train, args.validation\n",
    "    parse_csv = \"?format=csv&label_column=0\"\n",
    "    dtrain = xgboost.DMatrix(train+parse_csv)\n",
    "    dval = xgboost.DMatrix(validation+parse_csv)\n",
    "\n",
    "    # enable auto logging\n",
    "    mlflow.xgboost.autolog()\n",
    "\n",
    "    watchlist = [(dtrain, \"train\"), (dval, \"validation\")]\n",
    "    with mlflow.start_run():\n",
    "        params = {\n",
    "            \"max_depth\": args.max_depth,\n",
    "            \"eta\": args.eta,\n",
    "            \"gamma\": args.gamma,\n",
    "            \"min_child_weight\": args.min_child_weight,\n",
    "            \"subsample\": args.subsample,\n",
    "            \"silent\": args.silent,\n",
    "            \"objective\": args.objective}\n",
    "\n",
    "        # The output_uri is a the URI for the s3 bucket where the metrics will be\n",
    "        # saved.\n",
    "        output_uri = (\n",
    "            args.smdebug_path\n",
    "            if args.smdebug_path is not None\n",
    "            else args.output_uri\n",
    "        )\n",
    "\n",
    "        collections = (\n",
    "            args.smdebug_collections.split(',')\n",
    "            if args.smdebug_collections is not None\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        hook = create_smdebug_hook(\n",
    "            out_dir=output_uri,\n",
    "            frequency=args.smdebug_frequency,\n",
    "            collections=collections,\n",
    "            train_data=dtrain,\n",
    "            validation_data=dval,\n",
    "        )\n",
    "\n",
    "        model = xgboost.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            evals=watchlist,\n",
    "            num_boost_round=args.num_round,\n",
    "            callbacks=[hook])\n",
    "\n",
    "        if not os.path.exists(args.model_dir):\n",
    "            os.makedirs(args.model_dir)\n",
    "\n",
    "        model_location = os.path.join(args.model_dir, 'xgboost-model')\n",
    "        pickle.dump(model, open(model_location, 'wb'))\n",
    "\n",
    "        mlflow.xgboost.log_model(model, 'model', registered_model_name='xgb-customer-churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "training"
    ]
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)\n",
    "try:\n",
    "    run_training()\n",
    "except Exception as e:\n",
    "    logger.exception(\"Unable to execute training\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "ignore",
     "predictor"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[0.011914667673408985]'\n",
      "b'[0.008735105395317078]'\n",
      "b'[0.15768414735794067]'\n",
      "b'[0.008569112047553062]'\n",
      "b'[0.023335663601756096]'\n",
      "b'[0.6892004609107971]'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-eb32b45e3af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "from sagemaker.predictor import csv_serializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "endpoint_name = 'dev-xgb-customer-churn-v2'\n",
    "\n",
    "\n",
    "predictor = RealTimePredictor(endpoint=endpoint_name, sagemaker_session=sess, serializer=csv_serializer,\n",
    "                                content_type=CONTENT_TYPE_CSV)\n",
    "\n",
    "column_names = \"Account Length,VMail Message,Day Mins,Day Calls,Eve Mins,Eve Calls,Night Mins,Night Calls,Intl Mins,Intl Calls,CustServ Calls,State_AK,State_AL,State_AR,State_AZ,State_CA,State_CO,State_CT,State_DC,State_DE,State_FL,State_GA,State_HI,State_IA,State_ID,State_IL,State_IN,State_KS,State_KY,State_LA,State_MA,State_MD,State_ME,State_MI,State_MN,State_MO,State_MS,State_MT,State_NC,State_ND,State_NE,State_NH,State_NJ,State_NM,State_NV,State_NY,State_OH,State_OK,State_OR,State_PA,State_RI,State_SC,State_SD,State_TN,State_TX,State_UT,State_VA,State_VT,State_WA,State_WI,State_WV,State_WY,Area Code_408,Area Code_415,Area Code_510,Int'l Plan_no,Int'l Plan_yes,VMail Plan_no,VMail Plan_yes\\n\"\n",
    "\n",
    "with open('test-data/test_sample.csv', 'r') as f:\n",
    "    for row in f:\n",
    "        payload_orig = row.rstrip('\\n')\n",
    "        payload = row.rstrip('\\n')\n",
    "        payload = column_names + payload\n",
    "        response = predictor.predict(data=payload)\n",
    "        print(response)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn,Account Length,VMail Message,Day Mins,Day Calls,Eve Mins,Eve Calls,Night Mins,Night Calls,Intl Mins,Intl Calls,CustServ Calls,State_AK,State_AL,State_AR,State_AZ,State_CA,State_CO,State_CT,State_DC,State_DE,State_FL,State_GA,State_HI,State_IA,State_ID,State_IL,State_IN,State_KS,State_KY,State_LA,State_MA,State_MD,State_ME,State_MI,State_MN,State_MO,State_MS,State_MT,State_NC,State_ND,State_NE,State_NH,State_NJ,State_NM,State_NV,State_NY,State_OH,State_OK,State_OR,State_PA,State_RI,State_SC,State_SD,State_TN,State_TX,State_UT,State_VA,State_VT,State_WA,State_WI,State_WV,State_WY,Area Code_408,Area Code_415,Area Code_510,Int'l Plan_no,Int'l Plan_yes,VMail Plan_no,VMail Plan_yes\r\n",
      "0,106,0,274.4,120,198.6,82,160.8,62,6.0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0\r\n",
      "0,28,0,187.8,94,248.6,86,208.8,124,10.6,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,1,0\r\n",
      "1,148,0,279.3,104,201.6,87,280.8,99,7.9,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0\r\n",
      "0,132,0,191.9,107,206.9,127,272.0,88,12.6,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0\r\n",
      "0,92,29,155.4,110,188.5,104,254.9,118,8.0,4,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1\r\n",
      "0,131,25,192.7,85,225.9,105,254.2,59,10.9,6,2,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1\r\n",
      "0,69,0,143.6,88,141.8,86,194.0,83,10.8,5,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0\r\n",
      "0,93,0,114.3,100,221.1,103,126.3,88,10.9,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0\r\n",
      "0,90,0,193.7,83,154.2,79,299.0,60,12.7,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0\r\n"
     ]
    }
   ],
   "source": [
    "!head 'test-data/training-dataset-with-header.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CodePipeline](codepipeline.png \"Sample CodePipeline View\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132,25,113.2,96,269.9,107,229.1,87,7.1,7,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1\r\n",
      "112,17,183.2,95,252.8,125,156.7,95,9.7,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1\r\n",
      "91,24,93.5,112,183.4,128,240.7,133,9.9,3,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1\r\n",
      "22,0,110.3,107,166.5,93,202.3,96,9.5,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0\r\n",
      "102,0,186.8,92,173.7,123,250.9,131,9.7,4,2,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0\r\n",
      "118,21,156.5,122,209.2,125,158.7,81,11.1,3,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1\r\n",
      "178,35,175.4,88,190.0,65,138.7,94,10.5,3,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1\r\n",
      "107,0,234.1,91,163.1,105,282.5,100,10.0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0\r\n",
      "94,0,207.0,109,167.4,80,238.2,117,2.6,6,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,1,0\r\n",
      "86,33,253.1,112,210.1,94,95.0,98,11.9,4,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CodePipeline](codepipeline.png \"Sample CodePipeline View\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "177px",
    "width": "335px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
